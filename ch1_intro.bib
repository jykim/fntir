
@article{INR-009,
	url = {http://dx.doi.org/10.1561/1500000009},
	year = {2010},
	volume = {4},
	journal = {Foundations and Trends® in Information Retrieval},
	title = {Test Collection Based Evaluation of Information Retrieval Systems},
	doi = {10.1561/1500000009},
	issn = {1554-0669},
	number = {4},
	pages = {247-375},
	author = {Mark Sanderson}
}

@article{INR-XYZ,
	year = {2016},
	journal = {Foundations and Trends® in Information Retrieval},
	title = {Online Evaluation for Information Retrieval},
	author = {Katja Hofmann, Lihong Li, Filip Radlinski}
}

@article{kelly2009methods,
	title={Methods for evaluating interactive information retrieval systems with users},
	author={Kelly, Diane},
	journal={Foundations and Trends in Information Retrieval},
	volume={3},
	number={1—2},
	pages={1--224},
	year={2009},
	publisher={Now Publishers Inc.}
}


%% Log Study

@inproceedings{li2010contextual,
	title={A contextual-bandit approach to personalized news article recommendation},
	author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
	booktitle={Proceedings of the 19th international conference on World wide web},
	pages={661--670},
	year={2010},
	organization={ACM}
}

@book{
	chuklin2015click,
	Author = {Chuklin, Aleksandr and Markov, Ilya and de Rijke, Maarten},
	Publisher = {Morgan \& Claypool},
	Title = {Click Models for Web Search},
	Year = {2015},
	Isbn = {9781627056489},
	Doi = {10.2200/S00654ED1V01Y201507ICR043}
}

@inproceedings{Li:2015,
	author = {Li, Lihong and Kim, Jin Young and Zitouni, Imed},
	title = {Toward Predicting the Outcome of an A/B Experiment for Search Relevance},
	booktitle = {Proceedings of the Eighth ACM International Conference on Web Search and Data Mining},
	series = {WSDM '15},
	year = {2015},
	isbn = {978-1-4503-3317-7},
	location = {Shanghai, China},
	pages = {37--46},
	numpages = {10},
	url = {http://doi.acm.org/10.1145/2684822.2685311},
	doi = {10.1145/2684822.2685311},
	acmid = {2685311},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {contextual bandits, evaluation, experimentation, information retrieval, web search},
} 


%% IR Evaluation

@article{borlund2003,
	address = {New York, NY, USA},
	author = {Borlund, Pia},
	day = {7},
	issn = {1532-2882},
	journal = {Journal of the American Society for Information Science and Technology},
	month = {May},
	number = {10},
	pages = {913--925},
	posted-at = {2010-11-09 14:48:14},
	priority = {2},
	publisher = {John Wiley \& Sons, Inc.},
	title = {{The concept of relevance in IR}},
	volume = {54},
	year = {2003}
}


@Article{cleverdon67,
	author =	 {C. W. Cleverdon},
	title =	 {The Cranfield tests on index language devices},
	journal =	 {Aslib},
	year =	 1967,
	volume =	 19,
	pages =	 {173--192}
}

@article{rel-hist-jasis-97,
	author    = {Stefano Mizzaro},
	title     = {Relevance: The Whole History},
	journal   = {Journal of the American Society for Information Science},
	volume    = {48},
	number    = {9},
	year      = {1997},
	pages     = {810-832},
	bibsource = {DBLP, http://dblp.uni-trier.de}
}


@Book{voor:trec05,
	editor =	 "Ellen M. Voorhees and Donna K. Harman",
	title =	 {{TREC}: Experimentation and Evaluation in Information Retrieval},
	booktitle =	 {TREC: Experimentation and Evaluation in
	Information Retrieval},
	publisher =	 "MIT Press",
	year =	 2005
}

@InProceedings{scholer13,
	author = "Falk Scholer and Alistair Moffat and Paul Thomas",
	title = "Choices in batch information retrieval evaluation",
	booktitle = "Proceedings of the Australasian Document Computing Symposium",
	year = 2013
}
